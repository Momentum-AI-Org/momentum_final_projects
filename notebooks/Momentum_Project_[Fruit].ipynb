{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Momentum Project [Fruit].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuTo64Pofs1T"
      },
      "outputs": [],
      "source": [
        "#@title Hidden Code (Run Me!)\n",
        "### DO NOT CHANGE ###\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "! git clone https://github.com/Momentum-AI-Org/momentum_final_projects.git\n",
        "%cd momentum_final_projects \n",
        "! pip install -e .\n",
        "\n",
        "from api.config import ProjectConfig\n",
        "from api.setup_script import setup_script\n",
        "from utils.constants import PROJECT_TYPE\n",
        "\n",
        "# one of SHOES, FRUIT, PIZZA, RECAPTCHA, WEATHER\n",
        "ProjectConfig.PROJECT_NAME = PROJECT_TYPE.FRUIT\n",
        "setup_script()\n",
        "\n",
        "from api.common import (\n",
        "    download_data,\n",
        "    get_train_test_datasets,\n",
        "    get_model,\n",
        "    train_model,\n",
        "    display_loss_curves,\n",
        "    visualize_dataset,\n",
        "    evaluate_pretrain_accuracy,\n",
        "    evaluate_test_accuracy,\n",
        "    visualize_predictions,\n",
        ")\n",
        "### DO NOT CHANGE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fruit Classifier Project\n",
        "Welcome to the Fruit Classifier project! In this project, you'll be building a classifier (a convolutional neural network) to identify different types of fruit from images. You'll be using a lot of knowledge you've learned over the past week, so feel free to use those materials as you work on your project. As always, feel free to ask your mentors quesitons if you're stuck (that's what they're here for)."
      ],
      "metadata": {
        "id": "M_-6mUQM9hTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project will have the following structure:\n",
        "1. Downloading the dataset\n",
        "2. Building the train/test datasets\n",
        "3. Looking at the dataset\n",
        "4. Building our model\n",
        "5. Choosing the hyperparameters\n",
        "6. Training our model\n",
        "7. Evaluating our model\n",
        "8. Seeing our model's predictions!"
      ],
      "metadata": {
        "id": "HiGBW--f9vyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions!\n",
        "\n",
        "There are predefined function to walk you through this lab. \n",
        "\n",
        " **Hint: the functions are presented in the order you should use them!**\n",
        "\n",
        "<br/>\n",
        "\n",
        "`download_data()`\n",
        "- This downloads the fruit dataset you need! \n",
        "- This function takes in no parameters and dosen't return anything.\n",
        "\n",
        "<br/>\n",
        "\n",
        "`get_train_test_datasets(num_train_imgs_per_class, num_test_imgs_per_class) -> train_dataset, test_dataset`\n",
        "- Creates a train and test dataset. \n",
        "- You pass in how many images you want the train and test datasets to contain (`num_train_imgs_per_class` and `num_test_imgs_per_class`) this function will return a `train_dataset` and a `test_dataset`. \n",
        "- Try training with `100` images and testing with `25` images to begin, and increase from there.\n",
        "- Note that if you try to make the datasets too big (and there aren't enough downloaded images), this function will throw an error.\n",
        "\n",
        "<br/>\n",
        "\n",
        "`visualize_dataset(dataset)`\n",
        "- This function takes in one parameter, which is the `dataset` you want to visualize.\n",
        "- This function dosen't return anything.\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "`get_model(depth, num_filters) -> model`\n",
        "- This function takes in two parameters.\n",
        "- `depth` controls the number of layers that your network has. More depth corresponds to a larger and more complex network, but is slower to train. Try keeping this value in the range `(4, 8)`.\n",
        "- `num_filters` controls the number of filters that your network has (think back to convolutional neural networks!). More filters corresponds to a larger and more complex network, but is slower to train. Try keeping this value in the range `(128, 512)`.\n",
        "- This function returns an untrained neural network `model`.\n",
        "\n",
        "<br/>\n",
        "\n",
        "`evaluate_pretrain_accuracy(model, test_dataset) -> pretrained_accuracy`\n",
        "- This function takes in your `model` and `test_dataset` and returns how accurate your model is at classifying the images correctly (`pretrained_accuracy`).\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "`train_model(model, train_dataset, test_dataset, n_epochs, lr)`\n",
        "- This function takes in several parameters:\n",
        "- `model` your untrained model\n",
        "- `train_dataset` dataset to use for training\n",
        "- `test_dataset` dataset to use for testing\n",
        "- `n_epochs` number of times to loop through the `train_dataset` during training. We suggest keeping this value between `(10, 60)`\n",
        "- `lr` the learning rate to use during training (remember going down the hill!). We suggest keeping this value between `(0.01, 0.0001)`\n",
        "- This function dosen't return anything, but edits your existing model to make it better!\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "`display_loss_curves()`\n",
        "- This function will display pretty loss curves after you finish training your model! Helpful to detect overfitting!\n",
        "- This function does not have any parameters, nor does it return anything.\n",
        "\n",
        "<br/>\n",
        "\n",
        "`evaluate_test_accuracy(model, test_dataset) -> test_accuracy`\n",
        "- This function takes in your `model` and `test_dataset` and returns how accurate your model is at classifying the images correctly (`test_accuracy`).\n",
        "\n",
        "<br/>\n",
        "\n",
        "`visualize_predictions(model, test_dataset)`\n",
        "- This function takes in your `model` and `test_dataset` and will create a pretty graphic of your model's predictions!\n",
        "- This function dosen't return anything."
      ],
      "metadata": {
        "id": "KnA64u2f99Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Data\n",
        "\n",
        "Machine learning is all about data, so lets start by getting some data! Unfortunately, our dataset lives online -- lets download it using one of the functions above :) \n",
        "\n",
        "Fill in the code box below to download the image data to our colab notebook. Wait until the code below finishes running."
      ],
      "metadata": {
        "id": "IGKsXUIvEYGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( our solution is just one line of code :D )"
      ],
      "metadata": {
        "id": "HzM5a16HnsOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the Data Into Datasets\n",
        "\n",
        "The downloaded data is messy, so we've done some of the grunt work to clean it up for you! Call the right function below to create a `train_dataset` and `test_dataset`. We will train our model on the `train_dataset` and evaluate it on the `test_dataset`.\n",
        "\n",
        "**Why do we want to split our data into two datasets? Hint: it has to do with overfitting!**"
      ],
      "metadata": {
        "id": "1u_IqStuE6zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( our solution is just one line of code :D )"
      ],
      "metadata": {
        "id": "ldWEJck6KCto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking at our Data\n",
        "\n",
        "That was a lot of data we just downloaded, processed, and organized! But how do we know we downloaded the right thing? Well, we can look at the data!\n",
        "\n",
        "Try visualizing your `train_dataset` and `test_dataset` below!\n",
        "\n",
        "Consider the following:\n",
        "- Does the data look like what you expected? \n",
        "- Whats in the foreground of the images that you see?\n",
        "- Whats in the background?\n",
        "- What colors are the objects in the images that you see? Is there one color that stands out?\n",
        "- Are the images blurry or clear?\n",
        "\n",
        "Be critical about your data because your model can only ever be as good as your data!"
      ],
      "metadata": {
        "id": "tmADRLB2Fv0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( visualizing each dataset can be done in one line of code :D )"
      ],
      "metadata": {
        "id": "n_7N-20kcex8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an Untrained Model\n",
        "\n",
        "We're ready to build our model! You get to decide how complex to make your model (tune `depth` and `num_filters` accordingly, after first reading the documentation above). \n",
        "\n",
        "Remember: simpler models are much faster to train, but larger ones can capture more of the details and patterns in your data!"
      ],
      "metadata": {
        "id": "VfDprNx_HD1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( our solution is just one line of code :D )"
      ],
      "metadata": {
        "id": "24jbNhFoKXoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Our Untrained Model\n",
        "\n",
        "Let's see how well our untrained model does! It shouldn't do much better than random guessing..."
      ],
      "metadata": {
        "id": "qZRLQFK6H24S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( our solution is just one line of code :D )"
      ],
      "metadata": {
        "id": "90dUBnYEcjBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Time\n",
        "\n",
        "Now for the exciting part! Lets train our model. \n",
        "Write the code below to train our model, and adjust the hyperparamerters, `n_epochs` and `lr` to your liking. \n",
        "\n",
        "Training the model will likely take a while depending on the parameters you chose (up to 15 minutes)! This may be a great time to \n",
        "- eat a snack\n",
        "- use the bathroom\n",
        "- talk to a friend\n",
        "- go outside\n",
        "\n",
        "... but remember to keep an eye on your training loss to see if your model is improving!"
      ],
      "metadata": {
        "id": "4IcESrLWIDPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here! ( our solution is just one line of code :D )"
      ],
      "metadata": {
        "id": "ifkopB46KaQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate our Model\n",
        "We can evaluate our model in 3 ways.\n",
        "\n",
        "1. We can look at the loss curves during training \n",
        "2. We can compute our model's overall test accuracy\n",
        "3. We can see some sample predictions that our model makes\n",
        "\n",
        "(each of these is a separate function)\n",
        "\n",
        "<br/>\n",
        "\n",
        "### What to look for\n",
        "Machine learning is sometimes more of an art than a science. Heres what to watch out for:\n",
        "1. You want to make sure you training loss is steadily deacreasing, and your validation accuracy is steadily increasing.\n",
        "  - If your training loss is jumping around your learning rate may be too high.\n",
        "  - If your validation loss starts to decrease late into training it can be a sign of overfitting!\n",
        "\n",
        "2.  These are hard problems and we are limited by time! Don't worry about making your accuracy perfect. Try for over `60%` :)\n",
        "\n",
        "3. See if there is a pattern to the mistakes your model is making.\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "### Improving Your Model\n",
        "\n",
        "There are several numbers you can play around with to try to boost your model's performance:\n",
        "\n",
        "1. Change your dataset size (number of images)\n",
        "2. Change your model's complexity (depth and # of filters)\n",
        "3. Change your training time (# of epochs)\n",
        "\n",
        "If you're stuck, ask a mentor for help!"
      ],
      "metadata": {
        "id": "juM_SBRrJxE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Loss Curves"
      ],
      "metadata": {
        "id": "qeLpWgLKKM5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_loss_curves()"
      ],
      "metadata": {
        "id": "M04KFUPacoYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Test Accuracy"
      ],
      "metadata": {
        "id": "8NDxlSmBKRjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_test_accuracy(model, test_dataset)"
      ],
      "metadata": {
        "id": "azWI-juzcx8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Predictions"
      ],
      "metadata": {
        "id": "JVJQOD7pKTuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(model, test_dataset)"
      ],
      "metadata": {
        "id": "MJ4nRxP5cz2u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}